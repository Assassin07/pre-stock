"""
æ•°æ®é¢„å¤„ç†æ¨¡å—
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import joblib
import os
from config import DATA_CONFIG, PATHS

# å°è¯•å¯¼å…¥æŠ€æœ¯æŒ‡æ ‡åº“ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåº
TALIB_AVAILABLE = False
TA_AVAILABLE = False

try:
    import talib
    TALIB_AVAILABLE = True
    print("âœ… ä½¿ç”¨ TA-Lib åº“è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
except ImportError:
    try:
        import ta
        TA_AVAILABLE = True
        print("âœ… ä½¿ç”¨ ta åº“è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
    except ImportError:
        print("âš ï¸ æœªå®‰è£…æŠ€æœ¯æŒ‡æ ‡åº“ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")


class StockDataPreprocessor:
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨"""
        self.scaler = MinMaxScaler()
        self.feature_columns = []
        self.sequence_length = DATA_CONFIG['sequence_length']
        self.prediction_days = DATA_CONFIG['prediction_days']
        
    def add_technical_indicators(self, df):
        """
        æ·»åŠ æŠ€æœ¯æŒ‡æ ‡

        Args:
            df: åŸå§‹è‚¡ç¥¨æ•°æ®

        Returns:
            DataFrame: æ·»åŠ æŠ€æœ¯æŒ‡æ ‡åçš„æ•°æ®
        """
        df = df.copy()

        if TALIB_AVAILABLE:
            return self._add_indicators_talib(df)
        elif TA_AVAILABLE:
            return self._add_indicators_ta(df)
        else:
            return self._add_indicators_simple(df)

    def _add_indicators_talib(self, df):
        """ä½¿ç”¨TA-Libåº“æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
        # åŸºç¡€ä»·æ ¼æ•°æ®
        high = df['high'].values
        low = df['low'].values
        close = df['close'].values
        volume = df['volume'].values
        open_price = df['open'].values

        # ç§»åŠ¨å¹³å‡çº¿
        df['ma5'] = talib.SMA(close, timeperiod=5)
        df['ma10'] = talib.SMA(close, timeperiod=10)
        df['ma20'] = talib.SMA(close, timeperiod=20)
        df['ma60'] = talib.SMA(close, timeperiod=60)

        # æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿
        df['ema12'] = talib.EMA(close, timeperiod=12)
        df['ema26'] = talib.EMA(close, timeperiod=26)

        # MACD
        df['macd'], df['macd_signal'], df['macd_hist'] = talib.MACD(close)

        # RSI
        df['rsi'] = talib.RSI(close, timeperiod=14)

        # å¸ƒæ—å¸¦
        df['bb_upper'], df['bb_middle'], df['bb_lower'] = talib.BBANDS(close, timeperiod=20)

        # KDJæŒ‡æ ‡
        df['k'], df['d'] = talib.STOCH(high, low, close)
        df['j'] = 3 * df['k'] - 2 * df['d']

        # å¨å»‰æŒ‡æ ‡
        df['wr'] = talib.WILLR(high, low, close, timeperiod=14)

        # æˆäº¤é‡æŒ‡æ ‡
        df['volume_ma5'] = talib.SMA(volume.astype(float), timeperiod=5)
        df['volume_ratio'] = df['volume'] / df['volume_ma5']

        # ä»·æ ¼å˜åŒ–ç‡
        df['price_change'] = df['close'].pct_change()
        df['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        df['open_close_ratio'] = (df['close'] - df['open']) / df['open']

        return df

    def _add_indicators_ta(self, df):
        """ä½¿ç”¨taåº“æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
        # ç§»åŠ¨å¹³å‡çº¿
        df['ma5'] = ta.trend.sma_indicator(df['close'], window=5)
        df['ma10'] = ta.trend.sma_indicator(df['close'], window=10)
        df['ma20'] = ta.trend.sma_indicator(df['close'], window=20)
        df['ma60'] = ta.trend.sma_indicator(df['close'], window=60)

        # æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿
        df['ema12'] = ta.trend.ema_indicator(df['close'], window=12)
        df['ema26'] = ta.trend.ema_indicator(df['close'], window=26)

        # MACD
        df['macd'] = ta.trend.macd_diff(df['close'])
        df['macd_signal'] = ta.trend.macd_signal(df['close'])
        df['macd_hist'] = df['macd'] - df['macd_signal']

        # RSI
        df['rsi'] = ta.momentum.rsi(df['close'], window=14)

        # å¸ƒæ—å¸¦
        bb = ta.volatility.BollingerBands(df['close'], window=20)
        df['bb_upper'] = bb.bollinger_hband()
        df['bb_middle'] = bb.bollinger_mavg()
        df['bb_lower'] = bb.bollinger_lband()

        # KDJæŒ‡æ ‡
        stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'])
        df['k'] = stoch.stoch()
        df['d'] = stoch.stoch_signal()
        df['j'] = 3 * df['k'] - 2 * df['d']

        # å¨å»‰æŒ‡æ ‡
        df['wr'] = ta.momentum.williams_r(df['high'], df['low'], df['close'], lbp=14)

        # æˆäº¤é‡æŒ‡æ ‡
        df['volume_ma5'] = ta.trend.sma_indicator(df['volume'], window=5)
        df['volume_ratio'] = df['volume'] / df['volume_ma5']

        # ä»·æ ¼å˜åŒ–ç‡
        df['price_change'] = df['close'].pct_change()
        df['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        df['open_close_ratio'] = (df['close'] - df['open']) / df['open']

        return df

    def _add_indicators_simple(self, df):
        """ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ï¼ˆä¸ä¾èµ–å¤–éƒ¨åº“ï¼‰"""
        print("âš ï¸ ä½¿ç”¨ç®€åŒ–ç‰ˆæŠ€æœ¯æŒ‡æ ‡è®¡ç®—")

        # ç§»åŠ¨å¹³å‡çº¿
        df['ma5'] = df['close'].rolling(window=5).mean()
        df['ma10'] = df['close'].rolling(window=10).mean()
        df['ma20'] = df['close'].rolling(window=20).mean()
        df['ma60'] = df['close'].rolling(window=60).mean()

        # æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿
        df['ema12'] = df['close'].ewm(span=12).mean()
        df['ema26'] = df['close'].ewm(span=26).mean()

        # ç®€åŒ–MACD
        df['macd'] = df['ema12'] - df['ema26']
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        df['macd_hist'] = df['macd'] - df['macd_signal']

        # ç®€åŒ–RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))

        # ç®€åŒ–å¸ƒæ—å¸¦
        df['bb_middle'] = df['close'].rolling(window=20).mean()
        bb_std = df['close'].rolling(window=20).std()
        df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
        df['bb_lower'] = df['bb_middle'] - (bb_std * 2)

        # ç®€åŒ–KDJ
        low_min = df['low'].rolling(window=9).min()
        high_max = df['high'].rolling(window=9).max()
        rsv = (df['close'] - low_min) / (high_max - low_min) * 100
        df['k'] = rsv.ewm(com=2).mean()
        df['d'] = df['k'].ewm(com=2).mean()
        df['j'] = 3 * df['k'] - 2 * df['d']

        # ç®€åŒ–å¨å»‰æŒ‡æ ‡
        df['wr'] = (high_max - df['close']) / (high_max - low_min) * -100

        # æˆäº¤é‡æŒ‡æ ‡
        df['volume_ma5'] = df['volume'].rolling(window=5).mean()
        df['volume_ratio'] = df['volume'] / df['volume_ma5']

        # ä»·æ ¼å˜åŒ–ç‡
        df['price_change'] = df['close'].pct_change()
        df['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        df['open_close_ratio'] = (df['close'] - df['open']) / df['open']

        return df
    
    def select_features(self, df):
        """
        é€‰æ‹©ç‰¹å¾åˆ—
        
        Args:
            df: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„æ•°æ®
            
        Returns:
            DataFrame: é€‰æ‹©çš„ç‰¹å¾æ•°æ®
        """
        # é€‰æ‹©ç”¨äºè®­ç»ƒçš„ç‰¹å¾
        feature_columns = [
            'open', 'high', 'low', 'close', 'volume',
            'ma5', 'ma10', 'ma20', 'ma60',
            'ema12', 'ema26',
            'macd', 'macd_signal', 'rsi',
            'bb_upper', 'bb_middle', 'bb_lower',
            'k', 'd', 'j', 'wr',
            'volume_ratio', 'price_change', 'high_low_ratio', 'open_close_ratio'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in df.columns]
        self.feature_columns = available_columns
        
        return df[available_columns]
    
    def create_sequences(self, data, target_column='close'):
        """
        åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®

        Args:
            data: ç‰¹å¾æ•°æ®
            target_column: ç›®æ ‡åˆ—å

        Returns:
            tuple: (X, y) åºåˆ—æ•°æ®å’Œç›®æ ‡æ•°æ®
        """
        X, y = [], []

        # è·å–ç›®æ ‡åˆ—çš„ç´¢å¼•
        if target_column in data.columns:
            target_idx = data.columns.get_loc(target_column)
        else:
            target_idx = 3  # é»˜è®¤ä½¿ç”¨closeåˆ—

        print(f"ğŸ“Š åˆ›å»ºåºåˆ—æ•°æ®: åºåˆ—é•¿åº¦={self.sequence_length}, é¢„æµ‹å¤©æ•°={self.prediction_days}")
        print(f"ğŸ¯ ç›®æ ‡åˆ—: {target_column} (ç´¢å¼•: {target_idx})")

        for i in range(self.sequence_length, len(data) - self.prediction_days + 1):
            # è¾“å…¥åºåˆ—
            X.append(data.iloc[i-self.sequence_length:i].values)

            # ç›®æ ‡å€¼ï¼ˆæœªæ¥å‡ å¤©çš„æ”¶ç›˜ä»·ï¼‰
            if self.prediction_days == 1:
                # å¦‚æœåªé¢„æµ‹1å¤©ï¼Œè¿”å›æ ‡é‡å€¼
                future_price = data.iloc[i, target_idx]
                y.append([future_price])  # åŒ…è£…æˆåˆ—è¡¨ä»¥ä¿æŒä¸€è‡´æ€§
            else:
                # é¢„æµ‹å¤šå¤©
                future_prices = data.iloc[i:i+self.prediction_days, target_idx].values
                y.append(future_prices)

        X = np.array(X)
        y = np.array(y)

        print(f"âœ… åºåˆ—æ•°æ®åˆ›å»ºå®Œæˆ: X.shape={X.shape}, y.shape={y.shape}")

        return X, y
    
    def normalize_data(self, data, fit_scaler=True):
        """
        æ•°æ®æ ‡å‡†åŒ–
        
        Args:
            data: è¾“å…¥æ•°æ®
            fit_scaler: æ˜¯å¦æ‹Ÿåˆç¼©æ”¾å™¨
            
        Returns:
            array: æ ‡å‡†åŒ–åçš„æ•°æ®
        """
        if fit_scaler:
            scaled_data = self.scaler.fit_transform(data)
        else:
            scaled_data = self.scaler.transform(data)
        
        return scaled_data
    
    def inverse_transform(self, data, target_column='close'):
        """
        åæ ‡å‡†åŒ–

        Args:
            data: æ ‡å‡†åŒ–çš„æ•°æ®
            target_column: ç›®æ ‡åˆ—åæˆ–ç´¢å¼•

        Returns:
            array: åæ ‡å‡†åŒ–åçš„æ•°æ®
        """
        try:
            # ç¡®ä¿æœ‰ç‰¹å¾åˆ—ä¿¡æ¯
            if not hasattr(self, 'feature_columns') or len(self.feature_columns) == 0:
                print("âš ï¸ ç‰¹å¾åˆ—ä¿¡æ¯ç¼ºå¤±ï¼Œè¿”å›åŸå§‹æ•°æ®")
                return data

            # è·å–ç›®æ ‡åˆ—ç´¢å¼•
            if isinstance(target_column, str):
                if target_column in self.feature_columns:
                    target_column_idx = self.feature_columns.index(target_column)
                else:
                    print(f"âš ï¸ ç›®æ ‡åˆ— '{target_column}' ä¸åœ¨ç‰¹å¾åˆ—ä¸­ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—")
                    # å¯»æ‰¾åŒ…å«'close'çš„åˆ—
                    close_cols = [i for i, col in enumerate(self.feature_columns) if 'close' in col.lower()]
                    if close_cols:
                        target_column_idx = close_cols[0]
                    else:
                        target_column_idx = 0  # ä½¿ç”¨ç¬¬ä¸€åˆ—
            else:
                target_column_idx = target_column

            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
            if target_column_idx >= len(self.feature_columns):
                print(f"âš ï¸ ç›®æ ‡åˆ—ç´¢å¼• {target_column_idx} è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—")
                target_column_idx = 0

            print(f"ğŸ”§ åæ ‡å‡†åŒ–: ä½¿ç”¨åˆ— '{self.feature_columns[target_column_idx]}' (ç´¢å¼•: {target_column_idx})")

            # åˆ›å»ºä¸åŸå§‹æ•°æ®ç›¸åŒå½¢çŠ¶çš„æ•°ç»„
            if len(data.shape) == 1:
                data_flat = data
                original_shape = data.shape
            else:
                data_flat = data.flatten()
                original_shape = data.shape

            dummy_data = np.zeros((len(data_flat), len(self.feature_columns)))
            dummy_data[:, target_column_idx] = data_flat

            # åæ ‡å‡†åŒ–
            inverse_data = self.scaler.inverse_transform(dummy_data)
            result = inverse_data[:, target_column_idx].reshape(original_shape)

            return result

        except Exception as e:
            print(f"âŒ åæ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {data.shape}")
            print(f"ğŸ“‹ ç‰¹å¾åˆ—æ•°: {len(self.feature_columns) if hasattr(self, 'feature_columns') else 0}")
            print("âš ï¸ è¿”å›åŸå§‹æ•°æ®")
            return data
    
    def prepare_data(self, df, target_column='close'):
        """
        å®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹
        
        Args:
            df: åŸå§‹è‚¡ç¥¨æ•°æ®
            target_column: ç›®æ ‡åˆ—å
            
        Returns:
            tuple: è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ•°æ®
        """
        print("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        df_with_indicators = self.add_technical_indicators(df)
        
        # é€‰æ‹©ç‰¹å¾
        feature_data = self.select_features(df_with_indicators)
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        feature_data = feature_data.dropna()
        
        print(f"ç‰¹å¾æ•°é‡: {len(self.feature_columns)}")
        print(f"æœ‰æ•ˆæ•°æ®ç‚¹: {len(feature_data)}")
        
        # æ•°æ®æ ‡å‡†åŒ–
        normalized_data = self.normalize_data(feature_data.values, fit_scaler=True)
        normalized_df = pd.DataFrame(normalized_data, columns=self.feature_columns, index=feature_data.index)
        
        # åˆ›å»ºåºåˆ—æ•°æ®
        X, y = self.create_sequences(normalized_df, target_column)
        
        print(f"åºåˆ—æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
        
        # åˆ†å‰²æ•°æ®é›†
        train_size = int(len(X) * DATA_CONFIG['train_ratio'])
        val_size = int(len(X) * DATA_CONFIG['val_ratio'])
        
        X_train = X[:train_size]
        y_train = y[:train_size]
        
        X_val = X[train_size:train_size + val_size]
        y_val = y[train_size:train_size + val_size]
        
        X_test = X[train_size + val_size:]
        y_test = y[train_size + val_size:]
        
        print(f"è®­ç»ƒé›†: {X_train.shape}, éªŒè¯é›†: {X_val.shape}, æµ‹è¯•é›†: {X_test.shape}")
        
        return (X_train, y_train), (X_val, y_val), (X_test, y_test)
    
    def save_scaler(self, filename='scaler.pkl'):
        """ä¿å­˜ç¼©æ”¾å™¨"""
        os.makedirs(PATHS['model_dir'], exist_ok=True)
        filepath = os.path.join(PATHS['model_dir'], filename)
        joblib.dump(self.scaler, filepath)
        print(f"ç¼©æ”¾å™¨å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_scaler(self, filename='scaler.pkl'):
        """åŠ è½½ç¼©æ”¾å™¨"""
        filepath = os.path.join(PATHS['model_dir'], filename)
        if os.path.exists(filepath):
            self.scaler = joblib.load(filepath)
            print(f"ç¼©æ”¾å™¨å·²åŠ è½½: {filepath}")
            return True
        return False
