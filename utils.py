"""
å·¥å…·å‡½æ•°æ¨¡å—
"""

import os
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import logging
from config import PATHS


def setup_logging(log_level=logging.INFO):
    """
    è®¾ç½®æ—¥å¿—é…ç½®
    
    Args:
        log_level: æ—¥å¿—çº§åˆ«
    """
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('stock_prediction.log'),
            logging.StreamHandler()
        ]
    )


def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    print("ğŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„...")

    for name, path in PATHS.items():
        try:
            os.makedirs(path, exist_ok=True)
            if os.path.exists(path):
                print(f"âœ… {name}: {path}")
            else:
                print(f"âŒ {name}: {path} - åˆ›å»ºå¤±è´¥")
        except Exception as e:
            print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {path}: {str(e)}")
            # å°è¯•ä½¿ç”¨ç»å¯¹è·¯å¾„
            try:
                abs_path = os.path.abspath(path)
                os.makedirs(abs_path, exist_ok=True)
                print(f"ğŸ”§ ä½¿ç”¨ç»å¯¹è·¯å¾„åˆ›å»º: {abs_path}")
            except Exception as e2:
                print(f"âŒ ç»å¯¹è·¯å¾„ä¹Ÿå¤±è´¥: {str(e2)}")

    print("ğŸ“‹ ç›®å½•æ£€æŸ¥å®Œæˆ")


def save_json(data, filename, directory=None):
    """
    ä¿å­˜JSONæ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        filename: æ–‡ä»¶å
        directory: ç›®å½•è·¯å¾„
    """
    if directory is None:
        directory = PATHS['results_dir']
    
    filepath = os.path.join(directory, filename)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)
    print(f"JSONæ–‡ä»¶å·²ä¿å­˜: {filepath}")


def load_json(filename, directory=None):
    """
    åŠ è½½JSONæ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        directory: ç›®å½•è·¯å¾„
        
    Returns:
        dict: åŠ è½½çš„æ•°æ®
    """
    if directory is None:
        directory = PATHS['results_dir']
    
    filepath = os.path.join(directory, filename)
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"JSONæ–‡ä»¶å·²åŠ è½½: {filepath}")
        return data
    else:
        print(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return None


def save_pickle(data, filename, directory=None):
    """
    ä¿å­˜Pickleæ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        filename: æ–‡ä»¶å
        directory: ç›®å½•è·¯å¾„
    """
    if directory is None:
        directory = PATHS['model_dir']
    
    filepath = os.path.join(directory, filename)
    with open(filepath, 'wb') as f:
        pickle.dump(data, f)
    print(f"Pickleæ–‡ä»¶å·²ä¿å­˜: {filepath}")


def load_pickle(filename, directory=None):
    """
    åŠ è½½Pickleæ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        directory: ç›®å½•è·¯å¾„
        
    Returns:
        object: åŠ è½½çš„æ•°æ®
    """
    if directory is None:
        directory = PATHS['model_dir']
    
    filepath = os.path.join(directory, filename)
    if os.path.exists(filepath):
        with open(filepath, 'rb') as f:
            data = pickle.load(f)
        print(f"Pickleæ–‡ä»¶å·²åŠ è½½: {filepath}")
        return data
    else:
        print(f"Pickleæ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return None


def calculate_returns(prices):
    """
    è®¡ç®—æ”¶ç›Šç‡
    
    Args:
        prices: ä»·æ ¼åºåˆ—
        
    Returns:
        numpy.ndarray: æ”¶ç›Šç‡åºåˆ—
    """
    if isinstance(prices, pd.Series):
        prices = prices.values
    
    returns = np.diff(prices) / prices[:-1]
    return returns


def calculate_volatility(returns, window=20):
    """
    è®¡ç®—æ³¢åŠ¨ç‡
    
    Args:
        returns: æ”¶ç›Šç‡åºåˆ—
        window: æ»šåŠ¨çª—å£å¤§å°
        
    Returns:
        numpy.ndarray: æ³¢åŠ¨ç‡åºåˆ—
    """
    if isinstance(returns, pd.Series):
        volatility = returns.rolling(window=window).std()
    else:
        volatility = pd.Series(returns).rolling(window=window).std().values
    
    return volatility


def calculate_sharpe_ratio(returns, risk_free_rate=0.03):
    """
    è®¡ç®—å¤æ™®æ¯”ç‡
    
    Args:
        returns: æ”¶ç›Šç‡åºåˆ—
        risk_free_rate: æ— é£é™©åˆ©ç‡
        
    Returns:
        float: å¤æ™®æ¯”ç‡
    """
    excess_returns = returns - risk_free_rate / 252  # å‡è®¾252ä¸ªäº¤æ˜“æ—¥
    sharpe_ratio = np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)
    return sharpe_ratio


def calculate_max_drawdown(prices):
    """
    è®¡ç®—æœ€å¤§å›æ’¤
    
    Args:
        prices: ä»·æ ¼åºåˆ—
        
    Returns:
        float: æœ€å¤§å›æ’¤
    """
    if isinstance(prices, pd.Series):
        prices = prices.values
    
    peak = np.maximum.accumulate(prices)
    drawdown = (prices - peak) / peak
    max_drawdown = np.min(drawdown)
    
    return max_drawdown


def validate_stock_code(stock_code):
    """
    éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    if not isinstance(stock_code, str):
        return False
    
    # Aè‚¡è‚¡ç¥¨ä»£ç æ ¼å¼éªŒè¯
    if len(stock_code) == 6 and stock_code.isdigit():
        return True
    
    return False


def get_trading_dates(start_date, end_date):
    """
    è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥è€ƒè™‘èŠ‚å‡æ—¥ï¼‰
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        list: äº¤æ˜“æ—¥æœŸåˆ—è¡¨
    """
    if isinstance(start_date, str):
        start_date = datetime.strptime(start_date, '%Y-%m-%d')
    if isinstance(end_date, str):
        end_date = datetime.strptime(end_date, '%Y-%m-%d')
    
    trading_dates = []
    current_date = start_date
    
    while current_date <= end_date:
        # æ’é™¤å‘¨æœ«
        if current_date.weekday() < 5:
            trading_dates.append(current_date)
        current_date += timedelta(days=1)
    
    return trading_dates


def normalize_features(data, method='minmax'):
    """
    ç‰¹å¾æ ‡å‡†åŒ–
    
    Args:
        data: è¾“å…¥æ•°æ®
        method: æ ‡å‡†åŒ–æ–¹æ³• ('minmax', 'zscore')
        
    Returns:
        tuple: (æ ‡å‡†åŒ–åçš„æ•°æ®, æ ‡å‡†åŒ–å‚æ•°)
    """
    if method == 'minmax':
        min_vals = np.min(data, axis=0)
        max_vals = np.max(data, axis=0)
        normalized_data = (data - min_vals) / (max_vals - min_vals + 1e-8)
        params = {'min_vals': min_vals, 'max_vals': max_vals}
    elif method == 'zscore':
        mean_vals = np.mean(data, axis=0)
        std_vals = np.std(data, axis=0)
        normalized_data = (data - mean_vals) / (std_vals + 1e-8)
        params = {'mean_vals': mean_vals, 'std_vals': std_vals}
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ‡å‡†åŒ–æ–¹æ³•: {method}")
    
    return normalized_data, params


def denormalize_features(data, params, method='minmax'):
    """
    ç‰¹å¾åæ ‡å‡†åŒ–
    
    Args:
        data: æ ‡å‡†åŒ–çš„æ•°æ®
        params: æ ‡å‡†åŒ–å‚æ•°
        method: æ ‡å‡†åŒ–æ–¹æ³•
        
    Returns:
        numpy.ndarray: åæ ‡å‡†åŒ–åçš„æ•°æ®
    """
    if method == 'minmax':
        min_vals = params['min_vals']
        max_vals = params['max_vals']
        denormalized_data = data * (max_vals - min_vals) + min_vals
    elif method == 'zscore':
        mean_vals = params['mean_vals']
        std_vals = params['std_vals']
        denormalized_data = data * std_vals + mean_vals
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ‡å‡†åŒ–æ–¹æ³•: {method}")
    
    return denormalized_data


def calculate_technical_signals(df):
    """
    è®¡ç®—æŠ€æœ¯åˆ†æä¿¡å·
    
    Args:
        df: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„æ•°æ®
        
    Returns:
        dict: æŠ€æœ¯ä¿¡å·
    """
    signals = {}
    
    # RSIä¿¡å·
    if 'rsi' in df.columns:
        latest_rsi = df['rsi'].iloc[-1]
        if latest_rsi > 70:
            signals['rsi'] = 'è¶…ä¹°'
        elif latest_rsi < 30:
            signals['rsi'] = 'è¶…å–'
        else:
            signals['rsi'] = 'ä¸­æ€§'
    
    # MACDä¿¡å·
    if 'macd' in df.columns and 'macd_signal' in df.columns:
        latest_macd = df['macd'].iloc[-1]
        latest_signal = df['macd_signal'].iloc[-1]
        if latest_macd > latest_signal:
            signals['macd'] = 'çœ‹æ¶¨'
        else:
            signals['macd'] = 'çœ‹è·Œ'
    
    # ç§»åŠ¨å¹³å‡çº¿ä¿¡å·
    if 'ma5' in df.columns and 'ma20' in df.columns:
        latest_ma5 = df['ma5'].iloc[-1]
        latest_ma20 = df['ma20'].iloc[-1]
        if latest_ma5 > latest_ma20:
            signals['ma'] = 'çœ‹æ¶¨'
        else:
            signals['ma'] = 'çœ‹è·Œ'
    
    return signals


def print_model_summary(model):
    """
    æ‰“å°æ¨¡å‹æ‘˜è¦ä¿¡æ¯
    
    Args:
        model: PyTorchæ¨¡å‹
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\næ¨¡å‹æ‘˜è¦:")
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    print(f"æ¨¡å‹ç»“æ„:")
    print(model)


def format_number(num, precision=2):
    """
    æ ¼å¼åŒ–æ•°å­—æ˜¾ç¤º
    
    Args:
        num: æ•°å­—
        precision: ç²¾åº¦
        
    Returns:
        str: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if abs(num) >= 1e8:
        return f"{num/1e8:.{precision}f}äº¿"
    elif abs(num) >= 1e4:
        return f"{num/1e4:.{precision}f}ä¸‡"
    else:
        return f"{num:.{precision}f}"


if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·å‡½æ•°
    create_directories()
    print("å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ")
