"""
è‚¡ç¥¨é¢„æµ‹æ¨¡å—
"""

import torch
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import os
from config import DATA_CONFIG, PATHS
from model import create_model
from data_preprocessor import StockDataPreprocessor


class StockPredictor:
    def __init__(self, model_type='lstm', input_size=20, output_size=5):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹
            input_size: è¾“å…¥ç‰¹å¾æ•°é‡
            output_size: è¾“å‡ºå¤§å°
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_type = model_type
        self.input_size = input_size
        self.output_size = output_size
        
        # åˆ›å»ºæ¨¡å‹
        self.model = create_model(model_type, input_size, output_size)
        self.model.to(self.device)
        
        # æ•°æ®é¢„å¤„ç†å™¨
        self.preprocessor = StockDataPreprocessor()
        
        # é¢„æµ‹ç»“æœ
        self.predictions = None
        self.actual_values = None
        
    def load_model(self, stock_code, is_best=True):
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            is_best: æ˜¯å¦åŠ è½½æœ€ä½³æ¨¡å‹
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        if is_best:
            filename = f"{stock_code}_best_model.pth"
        else:
            # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
            model_files = [f for f in os.listdir(PATHS['model_dir']) 
                          if f.startswith(f"{stock_code}_model_epoch_")]
            if not model_files:
                return False
            filename = sorted(model_files)[-1]
        
        filepath = os.path.join(PATHS['model_dir'], filename)
        
        if os.path.exists(filepath):
            checkpoint = torch.load(filepath, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            print(f"æ¨¡å‹å·²åŠ è½½: {filepath}")
            return True
        else:
            print(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return False
    
    def predict(self, X):
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            X: è¾“å…¥æ•°æ® (batch_size, sequence_length, input_size)
            
        Returns:
            numpy.ndarray: é¢„æµ‹ç»“æœ
        """
        self.model.eval()
        
        with torch.no_grad():
            if isinstance(X, np.ndarray):
                X = torch.FloatTensor(X)
            
            X = X.to(self.device)
            predictions = self.model(X)
            predictions = predictions.cpu().numpy()
        
        return predictions
    
    def predict_future(self, recent_data, days=5):
        """
        é¢„æµ‹æœªæ¥å‡ å¤©çš„è‚¡ä»·
        
        Args:
            recent_data: æœ€è¿‘çš„æ•°æ® (sequence_length, input_size)
            days: é¢„æµ‹å¤©æ•°
            
        Returns:
            numpy.ndarray: é¢„æµ‹çš„è‚¡ä»·
        """
        # ç¡®ä¿è¾“å…¥æ•°æ®å½¢çŠ¶æ­£ç¡®
        if len(recent_data.shape) == 2:
            recent_data = recent_data.reshape(1, recent_data.shape[0], recent_data.shape[1])
        
        predictions = self.predict(recent_data)
        
        # å¦‚æœé¢„æµ‹å¤©æ•°ä¸åŒ¹é…ï¼Œè¿›è¡Œè°ƒæ•´
        if predictions.shape[1] != days:
            if days <= predictions.shape[1]:
                predictions = predictions[:, :days]
            else:
                # å¦‚æœéœ€è¦æ›´å¤šå¤©æ•°ï¼Œä½¿ç”¨é€’å½’é¢„æµ‹
                predictions = self._recursive_predict(recent_data, days)
        
        return predictions[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
    
    def _recursive_predict(self, data, days):
        """
        é€’å½’é¢„æµ‹æ›´å¤šå¤©æ•°
        
        Args:
            data: è¾“å…¥æ•°æ®
            days: é¢„æµ‹å¤©æ•°
            
        Returns:
            numpy.ndarray: é¢„æµ‹ç»“æœ
        """
        all_predictions = []
        current_data = data.copy()
        
        remaining_days = days
        while remaining_days > 0:
            # é¢„æµ‹å½“å‰æ‰¹æ¬¡
            batch_predictions = self.predict(current_data)
            batch_size = min(remaining_days, batch_predictions.shape[1])
            
            all_predictions.append(batch_predictions[0, :batch_size])
            remaining_days -= batch_size
            
            if remaining_days > 0:
                # æ›´æ–°è¾“å…¥æ•°æ®ï¼Œä½¿ç”¨é¢„æµ‹å€¼ä½œä¸ºæ–°çš„è¾“å…¥
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„ç‰¹å¾å·¥ç¨‹
                new_features = np.zeros((1, batch_size, current_data.shape[2]))
                new_features[0, :, 3] = batch_predictions[0, :batch_size]  # å‡è®¾ç¬¬4åˆ—æ˜¯æ”¶ç›˜ä»·
                
                # æ»‘åŠ¨çª—å£æ›´æ–°
                current_data = np.concatenate([current_data[:, batch_size:, :], new_features], axis=1)
        
        return np.concatenate(all_predictions).reshape(1, -1)
    
    def evaluate(self, test_data, stock_code):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½

        Args:
            test_data: æµ‹è¯•æ•°æ® (X_test, y_test)
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            dict: è¯„ä¼°æŒ‡æ ‡
        """
        X_test, y_test = test_data

        print(f"ğŸ“Š è¯„ä¼°æ•°æ®å½¢çŠ¶: X_test={X_test.shape}, y_test={y_test.shape}")

        # è¿›è¡Œé¢„æµ‹
        predictions = self.predict(X_test)
        print(f"ğŸ”® é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")

        # åæ ‡å‡†åŒ–
        try:
            if hasattr(self.preprocessor, 'scaler') and self.preprocessor.scaler is not None:
                print("ğŸ”§ å¼€å§‹åæ ‡å‡†åŒ–...")
                predictions_denorm = self.preprocessor.inverse_transform(predictions, target_column='close')
                y_test_denorm = self.preprocessor.inverse_transform(y_test, target_column='close')
                print(f"âœ… åæ ‡å‡†åŒ–å®Œæˆ: pred={predictions_denorm.shape}, actual={y_test_denorm.shape}")
            else:
                print("âš ï¸ ç¼©æ”¾å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                predictions_denorm = predictions
                y_test_denorm = y_test
        except Exception as e:
            print(f"âŒ åæ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
            print("âš ï¸ ä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®è¿›è¡Œè¯„ä¼°")
            predictions_denorm = predictions
            y_test_denorm = y_test

        # ä¿å­˜é¢„æµ‹ç»“æœ
        self.predictions = predictions_denorm
        self.actual_values = y_test_denorm

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        try:
            # ç¡®ä¿æ•°æ®å½¢çŠ¶ä¸€è‡´
            if predictions_denorm.shape != y_test_denorm.shape:
                print(f"âš ï¸ è°ƒæ•´æ•°æ®å½¢çŠ¶: pred={predictions_denorm.shape}, actual={y_test_denorm.shape}")
                min_samples = min(predictions_denorm.shape[0], y_test_denorm.shape[0])
                if len(predictions_denorm.shape) > 1 and len(y_test_denorm.shape) > 1:
                    min_features = min(predictions_denorm.shape[1], y_test_denorm.shape[1])
                    predictions_denorm = predictions_denorm[:min_samples, :min_features]
                    y_test_denorm = y_test_denorm[:min_samples, :min_features]
                else:
                    predictions_denorm = predictions_denorm[:min_samples]
                    y_test_denorm = y_test_denorm[:min_samples]

            # åŸºæœ¬è¯„ä¼°æŒ‡æ ‡
            mse = np.mean((predictions_denorm - y_test_denorm) ** 2)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(predictions_denorm - y_test_denorm))

            # è®¡ç®—MAPEï¼ˆå¤„ç†é™¤é›¶æƒ…å†µï¼‰
            y_test_nonzero = y_test_denorm.copy()
            y_test_nonzero[y_test_nonzero == 0] = 1e-8  # é¿å…é™¤é›¶
            mape = np.mean(np.abs((y_test_denorm - predictions_denorm) / y_test_nonzero)) * 100

            # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡ï¼ˆä»…å½“æœ‰å¤šä¸ªæ—¶é—´æ­¥æ—¶ï¼‰
            if len(predictions_denorm.shape) > 1 and predictions_denorm.shape[1] > 1:
                pred_direction = np.sign(np.diff(predictions_denorm, axis=1))
                actual_direction = np.sign(np.diff(y_test_denorm, axis=1))
                direction_accuracy = np.mean(pred_direction == actual_direction) * 100
            else:
                # å•æ­¥é¢„æµ‹çš„æ–¹å‘å‡†ç¡®ç‡
                if len(predictions_denorm) > 1:
                    pred_direction = np.sign(np.diff(predictions_denorm.flatten()))
                    actual_direction = np.sign(np.diff(y_test_denorm.flatten()))
                    direction_accuracy = np.mean(pred_direction == actual_direction) * 100
                else:
                    direction_accuracy = 50.0  # é»˜è®¤å€¼

            metrics = {
                'MSE': float(mse),
                'RMSE': float(rmse),
                'MAE': float(mae),
                'MAPE': float(mape),
                'Direction_Accuracy': float(direction_accuracy)
            }

            print(f"\n{stock_code} æ¨¡å‹è¯„ä¼°ç»“æœ:")
            print(f"MSE: {mse:.6f}")
            print(f"RMSE: {rmse:.6f}")
            print(f"MAE: {mae:.6f}")
            print(f"MAPE: {mape:.2f}%")
            print(f"æ–¹å‘å‡†ç¡®ç‡: {direction_accuracy:.2f}%")

            return metrics

        except Exception as e:
            print(f"âŒ è¯„ä¼°æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

            # è¿”å›é»˜è®¤æŒ‡æ ‡
            return {
                'MSE': float('inf'),
                'RMSE': float('inf'),
                'MAE': float('inf'),
                'MAPE': float('inf'),
                'Direction_Accuracy': 50.0
            }
    
    def plot_predictions(self, stock_code, num_samples=100):
        """
        ç»˜åˆ¶é¢„æµ‹ç»“æœ
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            num_samples: æ˜¾ç¤ºçš„æ ·æœ¬æ•°é‡
        """
        if self.predictions is None or self.actual_values is None:
            print("æ²¡æœ‰é¢„æµ‹ç»“æœå¯æ˜¾ç¤º")
            return
        
        # é™åˆ¶æ˜¾ç¤ºçš„æ ·æœ¬æ•°é‡
        num_samples = min(num_samples, len(self.predictions))
        predictions = self.predictions[:num_samples]
        actual_values = self.actual_values[:num_samples]
        
        # åˆ›å»ºæ—¶é—´è½´
        time_steps = range(len(predictions))
        
        plt.figure(figsize=(15, 10))
        
        # ç»˜åˆ¶æ¯ä¸€å¤©çš„é¢„æµ‹
        for day in range(predictions.shape[1]):
            plt.subplot(2, 3, day + 1)
            plt.scatter(time_steps, actual_values[:, day], alpha=0.6, label='å®é™…å€¼', s=20)
            plt.scatter(time_steps, predictions[:, day], alpha=0.6, label='é¢„æµ‹å€¼', s=20)
            plt.title(f'ç¬¬{day+1}å¤©é¢„æµ‹')
            plt.xlabel('æ ·æœ¬')
            plt.ylabel('è‚¡ä»·')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # æ•´ä½“å¯¹æ¯”å›¾
        plt.subplot(2, 3, 6)
        plt.plot(actual_values.flatten(), label='å®é™…å€¼', alpha=0.7)
        plt.plot(predictions.flatten(), label='é¢„æµ‹å€¼', alpha=0.7)
        plt.title('æ•´ä½“é¢„æµ‹å¯¹æ¯”')
        plt.xlabel('æ—¶é—´æ­¥')
        plt.ylabel('è‚¡ä»·')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.suptitle(f'{stock_code} - é¢„æµ‹ç»“æœå¯¹æ¯”', fontsize=16)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        os.makedirs(PATHS['results_dir'], exist_ok=True)
        plt.savefig(os.path.join(PATHS['results_dir'], f'{stock_code}_predictions.png'), dpi=300, bbox_inches='tight')
        plt.show()
    
    def predict_next_days(self, stock_data, stock_code, days=5):
        """
        é¢„æµ‹æ¥ä¸‹æ¥å‡ å¤©çš„è‚¡ä»·

        Args:
            stock_data: è‚¡ç¥¨å†å²æ•°æ®
            stock_code: è‚¡ç¥¨ä»£ç 
            days: é¢„æµ‹å¤©æ•°

        Returns:
            dict: é¢„æµ‹ç»“æœ
        """
        try:
            print(f"ğŸ”® å¼€å§‹é¢„æµ‹ {stock_code} æœªæ¥ {days} å¤©...")

            # åŠ è½½é¢„å¤„ç†å™¨
            scaler_loaded = self.preprocessor.load_scaler(f'{stock_code}_scaler.pkl')
            if not scaler_loaded:
                print("âš ï¸ æ— æ³•åŠ è½½é¢„å¤„ç†å™¨ï¼Œä½¿ç”¨å½“å‰è®¾ç½®")

            # é¢„å¤„ç†æ•°æ®
            print("ğŸ”§ é¢„å¤„ç†æ•°æ®...")
            df_with_indicators = self.preprocessor.add_technical_indicators(stock_data)
            feature_data = self.preprocessor.select_features(df_with_indicators)
            feature_data = feature_data.dropna()

            print(f"ğŸ“Š ç‰¹å¾æ•°æ®å½¢çŠ¶: {feature_data.shape}")

            # æ ‡å‡†åŒ–
            if scaler_loaded:
                normalized_data = self.preprocessor.normalize_data(feature_data.values, fit_scaler=False)
            else:
                print("âš ï¸ é‡æ–°æ‹Ÿåˆç¼©æ”¾å™¨")
                normalized_data = self.preprocessor.normalize_data(feature_data.values, fit_scaler=True)

            # è·å–æœ€è¿‘çš„åºåˆ—æ•°æ®
            sequence_length = getattr(self.preprocessor, 'sequence_length', DATA_CONFIG['sequence_length'])
            if len(normalized_data) < sequence_length:
                print(f"âš ï¸ æ•°æ®ä¸è¶³ï¼Œè°ƒæ•´åºåˆ—é•¿åº¦: {sequence_length} -> {len(normalized_data)}")
                sequence_length = len(normalized_data)

            recent_sequence = normalized_data[-sequence_length:]
            print(f"ğŸ“ ä½¿ç”¨åºåˆ—é•¿åº¦: {sequence_length}")

            # è¿›è¡Œé¢„æµ‹
            predictions = self.predict_future(recent_sequence, days)
            print(f"ğŸ¯ é¢„æµ‹å½¢çŠ¶: {predictions.shape}")

            # åæ ‡å‡†åŒ–
            try:
                if len(predictions.shape) == 1:
                    predictions_reshaped = predictions.reshape(-1, 1)
                else:
                    predictions_reshaped = predictions.reshape(-1, 1) if predictions.shape[1] == 1 else predictions

                predictions_denorm = self.preprocessor.inverse_transform(predictions_reshaped, target_column='close')

                if len(predictions_denorm.shape) > 1:
                    predictions_denorm = predictions_denorm.flatten()

                print(f"âœ… åæ ‡å‡†åŒ–å®Œæˆ: {predictions_denorm.shape}")

            except Exception as e:
                print(f"âŒ åæ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
                print("âš ï¸ ä½¿ç”¨åŸå§‹é¢„æµ‹å€¼")
                predictions_denorm = predictions.flatten() if len(predictions.shape) > 1 else predictions

            # åˆ›å»ºé¢„æµ‹æ—¥æœŸ
            last_date = stock_data.index[-1]
            pred_dates = [last_date + timedelta(days=i+1) for i in range(len(predictions_denorm))]

            # è·å–æœ€åä»·æ ¼
            last_price = float(stock_data['close'].iloc[-1])

            # æ„å»ºç»“æœ
            result = {
                'dates': pred_dates,
                'predictions': predictions_denorm.tolist() if hasattr(predictions_denorm, 'tolist') else list(predictions_denorm),
                'last_price': last_price,
                'prediction_change': (predictions_denorm - last_price).tolist() if hasattr(predictions_denorm, 'tolist') else list(predictions_denorm - last_price)
            }

            print(f"âœ… é¢„æµ‹å®Œæˆï¼Œé¢„æµ‹äº† {len(predictions_denorm)} å¤©")
            return result

        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

            # è¿”å›é»˜è®¤ç»“æœ
            last_price = float(stock_data['close'].iloc[-1])
            pred_dates = [stock_data.index[-1] + timedelta(days=i+1) for i in range(days)]

            return {
                'dates': pred_dates,
                'predictions': [last_price] * days,
                'last_price': last_price,
                'prediction_change': [0.0] * days
            }
